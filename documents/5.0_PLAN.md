# Project Plan

## Overview
HS Code Classifier Application with 99.99% accuracy. Self-managed PostgreSQL database with Terraform + application for HS code classification.

**Company:** Israeli company serving worldwide customers  
**Business Model:** B2B (Business-to-Business)

**Environments:** Local development and staging only. Production environment will be added when client is secured.

## Final Application Goal: HS Code Classifier

**Target Accuracy:** 99.99%

**Core Features:**
1. **HS Code Classification:**
   - Classify product descriptions to HS codes with 99.99% accuracy using LLM with customs book rules context
   - **Classification based on known customs books** (country-specific, populated via LLM-based extraction from PDFs/text)
   - **Israel:** 3 customs books (verify and implement all 3)
   - **Other countries:** Different customs books and rules (support country-specific classification)
   - If HS code unknown, ask clarifying questions about the product to determine correct code (LLM-generated questions)
   - Reject abstract descriptions (e.g., "gift", vague terms) - LLM detects and replies that description is insufficient for classification

2. **Company Item Code Lists:**
   - Users can upload lists of company item codes with corresponding HS codes
   - If product description matches item in uploaded list, return HS code from list
   - Cost per transaction: X/D (where D = number of items in list, or similar division)

3. **Pricing Model:**
   - **Standard classification:** Cost X per transaction
   - **Company list lookup:** Cost X/D per transaction (reduced cost when using uploaded lists)
   - **Interactive/Abstract description:** Cost M×X per transaction (multiplier M for cases requiring questions or abstract description handling)

4. **Country-Specific Customs Books:**
   - Support multiple countries with their respective customs books
   - Israel: 3 customs books (primary focus)
   - Other countries: Different books and classification rules
   - User selects country/customs book before classification

5. **Service Access Methods (Unified Workflow):**
   All methods follow the same pattern:
   - User provides product description
   - User specifies customs book (optional, defaults if not provided)
   - System processes classification
   - User receives HS code result(s) for item(s)
   
   **Interactive Workflow Continuation (API Methods):**
   - If classification requires interactive questions, system returns session ID
   - User can continue workflow by sending session ID + answers via API
   - Process continues until classification is complete or session expires
   
   **Access Methods:**
   - **Frontend App:** Web interface for interactive classification with real-time Q&A
   - **Email to Email:** Send email with product description and customs book, receive email with HS code result(s)
   - **API Webhook (Asynchronous):** Fire-and-forget API call, receive result via webhook callback (or session ID if interactive). Continue workflow with session ID + answers
   - **API Synchronous:** Client waits for answer, immediate response with HS code(s) or questions. Continue workflow with session ID + answers

## Phase 1: Infrastructure (Terraform) ✅ COMPLETE
**Goal:** Provision full-stack application server (PostgreSQL + Backend + Frontend) on cost-effective provider

**Tasks:**
- [x] Terraform configuration (full-stack server)
- [x] Networking/security (firewall rules for HTTP, HTTPS, SSH, PostgreSQL, app port)
- [x] Server initialization (PostgreSQL, Node.js, Yarn, PM2)
- [x] Credentials/secrets (stored in .secrets file)
- [x] Backups/monitoring (backup strategy documented)
- [x] Test provisioning (server provisioned on DigitalOcean)

**Completed:** DigitalOcean droplet provisioned, PostgreSQL installed, Node.js 22 installed, firewall configured, secrets secured.

**Time:** 3-6 hours ✅  
**Cost:** $6/month initially (start with smallest droplet), upgrade to $12-24/month if performance requires it

## Phase 2: Database Schema ✅ SCHEMA STRUCTURE DEFINED
**Goal:** Define complete schema structure in `init.sql` for all application data (HS code classifier, B2B, users, groups, payments, etc.)

**Status:** Schema structure is defined (32 tables) but NOT YET APPLIED to database. Schema may need adjustments during implementation.

**Tasks:**
- [x] Create `init.sql` (single source of truth)
- [x] **User Management:**
  - [x] Users table (link to Clerk user IDs)
  - [x] User profiles and preferences
  - [x] User authentication metadata
- [x] **B2B/Organization:**
  - [x] Organizations table (link to Clerk organization IDs)
  - [x] Organization profiles and settings
  - [x] Organization members and roles
  - [x] Organization-level data isolation
  - [x] Groups/teams within organizations
- [x] **HS Code Classifier:**
  - [x] Classifications table (requests, results, status)
  - [x] Questions table (interactive Q&A sessions)
  - [x] Interactive workflow sessions table (session ID, status, questions asked, answers received, pending questions, expiration time)
  - [x] Customs books tables (country, book versions, HS codes, rules)
  - [x] Company item code lists (uploaded lists, item mappings, organization linkage)
  - [x] Transaction/pricing tables (track costs: X, X/D, M×X per transaction)
- [x] **Payments:**
  - [x] Payment accounts table (link to Payoneer, organization linkage)
  - [x] Payment transactions table (incoming/outgoing, status, currency)
  - [x] Invoices table (B2B invoice tracking, payment terms)
  - [x] Scheduled payments table (custom recurring payment logic)
- [x] **Service Access:**
  - [x] API keys and authentication tokens
  - [x] Webhook configurations (client webhook URLs)
  - [x] Job queue table (async API processing)
- [x] **Audit & Logging:**
  - [x] Audit logs table (user actions, classification history)
  - [x] Error logs table
- [x] Schema versioning system (schema_versions table for tracking schema changes)
  - **Note:** Migrations are NOT needed until production is running. All schema changes go into `init.sql` during planning/development.
- [x] Indexes and performance optimization
- [x] Document schema (README.md)

**Completed:** Schema structure defined with 32 tables, proper naming convention (table_name_field_name, singular), auto-increment primary keys, updated_at timestamps, and comprehensive indexes.

**Note:** Schema is defined but not yet applied to database. It will need to be applied and may require adjustments during implementation as we discover missing fields or relationships.

**Time:** 8-12 hours ✅

## Phase 3: Application Core Infrastructure
**Goal:** Core application infrastructure and database utilities

**Stack:** TypeScript (strict), Node.js, PostgreSQL (pg), tRPC, React (if UI), Global DRY CSS

**Tasks:**
- [ ] Database connection management (pg client, connection pooling)
- [ ] Query execution utilities (type-safe queries, error handling)
- [ ] CRUD operation helpers (reusable patterns)
- [ ] Database health checks
- [ ] Backup/restore utilities
- [ ] Multi-currency support utilities (for worldwide customers)
- [ ] Timezone handling utilities (for international customers)
- [ ] Organization/tenant isolation middleware (B2B multi-tenancy)
- [ ] Organization-level access control utilities
- [ ] Shared types and constants (from `src/shared/single-source.ts`)
- [ ] Error handling system (`AppError` pattern)
- [ ] Logging system integration
- [ ] Environment configuration (local/staging setup, environment variables)
- [ ] **Caching Strategy:** PostgreSQL's built-in caching (shared buffers) should be sufficient initially. Consider external cache (Redis) only if: high traffic volume, session data needs fast access, or rate limiting requires distributed counters. Start with PostgreSQL caching, add Redis later if needed.

**Time:** 8-12 hours

---

## Phase 3.1: HS Code Classifier Engine

**Goal:** Implement HS code classification system with 99.99% accuracy

**Tasks:**
- [ ] **LLM Integration (OpenAI & Other Providers):**
  - [ ] LLM provider abstraction layer: support multiple providers (OpenAI, Anthropic Claude, Google Gemini, xAI Grok, etc.)
  - [ ] OpenAI integration: API client, authentication, rate limiting
  - [ ] Anthropic Claude integration: API client, authentication, rate limiting
  - [ ] Google Gemini integration: API client, authentication, rate limiting
  - [ ] xAI Grok integration: API client, authentication, rate limiting
  - [ ] LLM provider selection logic: choose provider based on task, cost, or performance
  - [ ] LLM API key management: secure storage and rotation
  - [ ] LLM usage tracking: track tokens used, costs per request, provider used
  - [ ] LLM cost calculation: calculate cost per classification based on tokens used
  - [ ] LLM error handling: retry logic, fallback providers, error recovery
  - [ ] LLM response caching: cache similar requests to reduce costs
  - [ ] **LLM Tasks:**
    - [ ] HS code classification: use LLM with customs book rules context
    - [ ] Question generation: generate clarifying questions when HS code unknown
    - [ ] Abstract description detection: detect and reject vague/abstract descriptions
    - [ ] Product description analysis: validate and enhance product descriptions
    - [ ] Classification confidence scoring: LLM provides confidence scores
    - [ ] **Customs Book Data Extraction from PDFs/Text:**
      - [ ] PDF text extraction → LLM-based structured extraction (HS codes, descriptions, rules, hierarchical structure, country-specific codes, check digit algorithms)
      - [ ] LLM-based validation, transformation to database schema, batch processing, error handling
  - [ ] LLM prompt engineering: optimize prompts for each task (classification, questions, validation)
  - [ ] LLM model selection: choose appropriate models per task (GPT-4, GPT-3.5, Claude, Gemini, Grok, etc.)
  - [ ] LLM context optimization: manage token limits, truncate context intelligently
- [ ] Classification engine implementation (AI/ML model or rule-based system)
- [ ] Customs books integration (country-specific HS code databases)
- [ ] **Customs Book Rules Database & LLM Context:**
  - [ ] Populate `customs_books` and `customs_book_hs_codes` tables (via LLM-based extraction from PDFs/text)
  - [ ] Store classification rules in `customs_book_hs_code_country_rules` JSONB field
  - [ ] Create LLM context builder: retrieve relevant rules/codes from database, build context prompts, optimize for token limits
  - [ ] Test LLM classification accuracy with rules context (target 99.99%)
- [ ] Israel: 3 customs books integration and verification
- [ ] Multi-country customs book support
- [ ] Product description analysis and validation
- [ ] Abstract description detection (reject "gift", vague terms)
- [ ] Interactive question system (when HS code unknown)
- [ ] Question generation logic (ask clarifying questions about product)
- [ ] Interactive session management (create, track, continue sessions)
- [ ] Session state storage (questions asked, answers received, pending questions)
- [ ] Company item code list matching engine
- [ ] List upload and management system (CSV/Excel file upload, validation, parsing, storage)
- [ ] **Automated Customs Book Data Synchronization Mechanisms (Mehavizim):**
  - [ ] **Database Schema Enhancement:**
    - [ ] Sync tracking fields already added to `customs_books` table in `init.sql` (data_source_url, sync_status, last_sync_time, next_sync_scheduled_at, sync_error_message, sync_retry_count, sync_checksum, sync_metadata)
    - [ ] Sync indexes already created in `init.sql` (sync_status, next_sync_scheduled_at, last_sync_time)
  - [ ] Automated data download system: scripts to download customs data from official sources (WCO, country authorities)
    - [x] ✅ WCO PDF download script (`scripts/download-wco-pdfs.ts`) - **COMPLETED**
    - [ ] Other data source download scripts (EU TARIC, UK Trade Tariff, US HTSUS, Israel customs, etc.)
  - [ ] Data change detection: monitor official sources for new versions/updates (checksums, version numbers, publication dates)
  - [ ] Scheduled update jobs: cron jobs or scheduled tasks for regular data checks (monthly/quarterly)
  - [ ] Automated import pipeline: parse downloaded data (CSV, JSON, XML, PDF) and import into database
  - [ ] **LLM-Based Data Extraction** (see LLM Integration tasks above for details):
    - [ ] PDF text extraction → LLM-based structured extraction (HS codes, descriptions, rules, hierarchical structure, country-specific codes, check digit algorithms)
    - [ ] LLM-based data transformation and validation → Database import
    - [ ] Batch processing, error handling, cost tracking
  - [ ] Version management: automatically create new customs book versions when updates detected
  - [ ] Data validation: validate imported data (HS code formats, check digits, hierarchical relationships)
  - [ ] Update notifications: alert system when new customs book versions are available
  - [ ] Rollback mechanism: ability to revert to previous customs book version if import fails
  - [ ] Incremental updates: support partial updates (only changed HS codes) for efficiency
  - [ ] Multi-source support: handle different data sources (WCO, EU TARIC, UK Trade Tariff, US HTSUS, Israel customs, etc.)
  - [ ] Error handling & retry logic: handle network failures, rate limiting, and data source unavailability
  - [ ] Data freshness tracking: track last update time per customs book and data source
  - [ ] Automated rules extraction: parse classification rules from customs book data and store in `customs_book_hs_code_country_rules` JSONB field (using LLM for complex extraction)
- [ ] Customs books data management (import/load customs books data, versioning, updates)
- [ ] Customs books data source integration (how to obtain/update Israel's 3 books and other countries)
- [ ] Transaction cost calculation (X, X/D, M×X)
- [ ] Classification accuracy tracking and monitoring
- [ ] **Performance Optimization:** Use PostgreSQL's built-in caching for customs books (frequently accessed read-only data). Consider application-level caching only if performance testing shows bottlenecks.

**Time:** 20-30 hours

---

## Phase 3.2: Service Access Methods Implementation

**Goal:** Implement all four service access methods with unified workflow

**Common Workflow (All Access Methods):**
1. User provides product description
2. User specifies customs book (or defaults to user's default/Israel if not specified)
3. System processes classification (standard, list lookup, or interactive)
4. User receives HS code result(s) for item(s)

**Interactive Workflow Continuation (API Methods):**
- If classification requires interactive questions, system returns session ID
- User can continue workflow by sending session ID + answers via API
- Process continues until classification is complete or session expires

**Tasks:**
- [ ] **Frontend App:**
  - [ ] React UI for product description input
  - [ ] Customs book selection dropdown (with default option)
  - [ ] Interactive classification with real-time Q&A
  - [ ] Results display (HS code(s) for item(s))
  - [ ] Support for multiple items in single request
- [ ] **Email to Email:**
  - [ ] Mailgun inbound email handler
  - [ ] Parse email: extract product description and customs book (or use default)
  - [ ] Process classification (link to registered user if email matches)
  - [ ] Send result email with HS code(s) for item(s)
  - [ ] Support multiple items in email (one per line or structured format)
- [ ] **API Webhook (Async):**
  - [ ] POST endpoint: product description + customs book (optional, defaults if not provided)
  - [ ] **Workflow continuation:** POST endpoint with session ID + answers (if continuing interactive workflow)
  - [ ] Job queue system for background processing
  - [ ] Return job ID immediately (or session ID if interactive questions needed)
  - [ ] Process classification in background
  - [ ] Send result to client's webhook URL with HS code(s) for item(s) (or questions if interactive)
  - [ ] Support batch requests (multiple items)
  - [ ] Session management for interactive workflows (track questions, answers, state)
- [ ] **API Synchronous:**
  - [ ] POST endpoint: product description + customs book (optional, defaults if not provided)
  - [ ] **Workflow continuation:** POST endpoint with session ID + answers (if continuing interactive workflow)
  - [ ] Blocking API endpoint, client waits for response
  - [ ] Return HS code result(s) immediately (or questions if interactive needed)
  - [ ] Return session ID when interactive questions are needed (for continuation)
  - [ ] Support batch requests (multiple items)
  - [ ] Session management for interactive workflows (track questions, answers, state)
- [ ] User registration/authentication for all methods (Clerk integration)
- [ ] Default customs book logic (user preference, organization default, or system default)
- [ ] **Interactive workflow session management:**
  - [ ] Create session when interactive questions are needed
  - [ ] Store session state (session ID, questions, answers, status)
  - [ ] Session continuation endpoint (accept session ID + answers)
  - [ ] Session expiration/timeout handling
  - [ ] Session status tracking (active, completed, expired)
- [ ] API authentication and rate limiting (per user/organization limits, implementation details)
- [ ] Webhook signature verification
- [ ] Webhook retry logic (for failed async API webhook deliveries)
- [ ] Error handling for all access methods
- [ ] Session cleanup cron job (expire old interactive sessions)

**Time:** 15-20 hours

---

## Phase 3.5: Third-Party Integrations
**Goal:** Integrate all third-party services (Clerk, Payoneer, Mailgun, WhatsApp, LLM Providers)

**Third-Party Services:**
- **Clerk.com** - User authentication and management
- **Payoneer** - Payment processing and management
- **Mailgun** - Email sending/receiving (email-to-email HS code classification)
- **WhatsApp Business API (Meta)** - WhatsApp messaging for HS code classification
- **LLM Providers (OpenAI, Anthropic, Google, xAI Grok)** - AI/LLM services for HS code classification and related tasks

**Integration Tasks:**

**Clerk.com Integration:**
- [ ] Install and configure Clerk SDK
- [ ] Create ClerkWrapper (see [4.0_WRAPPERS_GUIDE.md](./4.0_WRAPPERS_GUIDE.md))
- [ ] Implement authentication middleware
- [ ] Set up webhook handler for user/organization events
- [ ] Configure Clerk organizations for B2B multi-tenant support
- [ ] Link database users table to Clerk user IDs (schema already in Phase 2)
- [ ] Link database organizations table to Clerk organization IDs (schema already in Phase 2)
- [ ] Implement organization-level data isolation middleware
- [ ] Implement protected routes with organization context
- [ ] Set up team member invitation system

**Payoneer Integration:**
- [ ] Obtain Payoneer API credentials
- [ ] Create PayoneerWrapper (see [4.0_WRAPPERS_GUIDE.md](./4.0_WRAPPERS_GUIDE.md))
- [ ] Implement payment request functionality (receiving payments)
- [ ] Implement bank transfer/payout functionality (sending money via ACH, SEPA, BACS, BECS)
- [ ] Implement payment method selection based on customer region
- [ ] Implement multi-currency support
- [ ] Implement payee registration and approval
- [ ] Implement payment status checking
- [ ] Set up webhook handler for payment events
- [ ] Link payments to users/organizations (database schema already in Phase 2)
- [ ] Implement invoice-based payment tracking
- [ ] Implement payment terms management (net 30, net 60, etc.)
- [ ] Implement organization-level payment accounts
- [ ] **Note:** Payoneer recurring payments not available (U.S. businesses only) - implement custom scheduling if needed

**Mailgun Integration (Email-to-Email HS Code Classification):**
- [ ] Obtain Mailgun API credentials
- [ ] Create MailgunWrapper (see [4.0_WRAPPERS_GUIDE.md](./4.0_WRAPPERS_GUIDE.md))
- [ ] Set up inbound email webhook handler
- [ ] Implement email parsing: extract product description and customs book (or use default)
- [ ] Link email to registered user (if email matches user account)
- [ ] Default customs book logic (user preference → organization default → system default)
- [ ] Support multiple items per email (one per line or structured format)
- [ ] Integrate with HS code classifier engine (Phase 3.1)
- [ ] Implement result email sending with HS code(s) for item(s)
- [ ] Configure domain and DNS settings

**WhatsApp Business API Integration:**
- [ ] Set up Meta Business Manager account
- [ ] Obtain WhatsApp Business API credentials
- [ ] Create WhatsAppBusinessWrapper (see [4.0_WRAPPERS_GUIDE.md](./4.0_WRAPPERS_GUIDE.md))
- [ ] Set up webhook handler for incoming messages
- [ ] Implement message template system
- [ ] Integrate with HS code classifier engine (Phase 3.1)
- [ ] Implement 24-hour messaging window handling

**See:** [9.0_INTEGRATIONS.md](./9.0_INTEGRATIONS.md) for detailed integration guide

**Time:** 12-18 hours

## Phase 4: Integration & Testing
**Goal:** Integrate all components and verify functionality

**Tasks:**
- [ ] Connect application to database (verify all connections)
- [ ] Test HS code classifier engine (accuracy, edge cases)
- [ ] Test all service access methods (frontend, email, API webhook, API sync)
- [ ] Test interactive workflow continuation (session management)
- [ ] Test third-party integrations (Clerk, Payoneer, Mailgun, WhatsApp)
- [ ] Test company item code list functionality
- [ ] Test pricing calculation (X, X/D, M×X)
- [ ] Test customs book selection and defaults
- [ ] Unit tests for core functions
- [ ] Integration tests for API endpoints
- [ ] End-to-end tests for complete workflows
- [ ] Performance testing (response times, concurrent requests)
- [ ] Error handling and edge case testing
- [ ] Load testing (high volume classification requests)
- [ ] Session cleanup testing (expired session handling)

**Time:** 10-14 hours

## Phase 5: Documentation
**Goal:** Complete project documentation

**Tasks:**
- [ ] API documentation (endpoints, request/response formats, authentication)
- [ ] Setup guide (environment setup, secrets configuration, database initialization)
- [ ] Deployment guide (infrastructure, staging deployment, monitoring)
- [ ] User guide (how to use each access method)
- [ ] Developer guide (code structure, contribution guidelines)
- [ ] Update README with final project status

**Time:** 4-6 hours

---

## Phase 6: Additional Features & Operations

**Goal:** Additional features and operational requirements

**Tasks:**
- [ ] **Billing & Invoicing:**
  - [ ] Transaction billing system (calculate costs per transaction)
  - [ ] Invoice generation (monthly/transaction-based invoices)
  - [ ] Payment collection integration (Payoneer)
  - [ ] Usage tracking and reporting (per user/organization)
- [ ] **Admin Panel/Dashboard:**
  - [ ] Admin interface for managing customs books
  - [ ] User/organization management dashboard
  - [ ] System monitoring dashboard (accuracy metrics, usage stats)
  - [ ] Customs books data import/update interface
- [ ] **Monitoring & Alerting:**
  - [ ] System health monitoring (database, API, classification engine)
  - [ ] Accuracy monitoring (track 99.99% target)
  - [ ] Performance metrics (response times, throughput)
  - [ ] Alerting system (errors, performance degradation, accuracy drops)
- [ ] **Operational Tasks:**
  - [ ] Backup and disaster recovery procedures
  - [ ] Customs books versioning system (handle updates without breaking classifications)
  - [ ] Model/engine update procedures (maintain 99.99% accuracy)
  - [ ] Scheduled jobs (session cleanup, report generation, data archiving)

**Time:** 15-25 hours

**Total:** 107-159 hours (including HS code classifier, integrations, and operations)

## Structure
```
apps/db-manager/
src/shared/     # types, utils, constants, single-source.ts
db/             # init.sql
infra/terraform/
```

## Dependencies
```
Phase 1 → Phase 2 → Phase 3 → Phase 3.1 → Phase 3.2 → Phase 3.5 → Phase 4 → Phase 5 → Phase 6
```

**Note:** 
- Phase 3.1 (HS Code Classifier Engine) depends on Phase 2 (Database Schema)
- Phase 3.2 (Service Access Methods) depends on Phase 3.1
- Phase 3.5 can be developed in parallel with Phase 3.1/3.2, but integration testing requires all to be complete
- Phase 6 (Additional Features & Operations) can be developed in parallel with earlier phases, but requires core functionality (Phases 3.1, 3.2, 3.5) to be complete

## Requirements
- Node.js 22+, Yarn, Terraform ≥ 1.7, psql
- TypeScript, PostgreSQL, Terraform knowledge
- Clerk.com account for user management
- Payoneer account for payment processing (worldwide support)
- Mailgun account for email-to-email HS code classification
- WhatsApp Business API account (Meta) for messaging
- LLM provider accounts (OpenAI, Anthropic, Google, xAI) for classification and data extraction
- Budget: $4-12/month (infrastructure) + service fees + LLM usage costs
- **HS Code Classifier Requirements:**
  - Access to customs books data (Israel: 3 books, other countries as needed)
  - LLM integration for classification and data extraction from PDFs/text
  - Classification engine (LLM-based with customs book rules context)
  - High accuracy target (99.99%)
- **International Considerations:** Multi-currency support, timezone handling, regional payment methods, country-specific customs books

## Success Criteria

**Core Functionality:**
✅ Database provisioned  
✅ HS code classifier achieves 99.99% accuracy  
✅ Interactive question system works when HS code unknown  
✅ Abstract descriptions properly rejected  
✅ Company item code lists upload and lookup functional  
✅ Transaction cost calculation accurate (X for standard, X/D for lists, M×X for interactive/abstract)  
✅ All access methods functional (frontend app, email-to-email, API webhook async, API sync)  
✅ All third-party integrations working (Clerk, Payoneer, Mailgun, WhatsApp, LLM Providers)

**Operations & Quality:**
✅ All operations work reliably  
✅ Performance meets requirements (response times, throughput)  
✅ Monitoring and alerting functional  
✅ Backup and disaster recovery procedures in place  
✅ Follows [1.0_PRINCIPLES.md](./1.0_PRINCIPLES.md)

---

## Quick Reference

**Total Development Time:** 107-159 hours  
**Infrastructure Cost:** $4-12/month + service fees  
**Key Technologies:** TypeScript, Node.js, PostgreSQL, tRPC, React  
**Third-Party Services:** Clerk, Payoneer, Mailgun, WhatsApp Business API, LLM Providers (OpenAI, Anthropic, Google, xAI Grok)  
**Primary Focus:** HS Code Classification with 99.99% accuracy for Israeli customs (3 books) and international support
